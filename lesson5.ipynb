{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9109b75",
   "metadata": {},
   "source": [
    "# One Time Setup\n",
    "\n",
    "Download learning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53c60d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import lib\n",
    "import os\n",
    "\n",
    "images_url = \"https://s3.amazonaws.com/fast-ai-imageclas/oxford-iiit-pet.tgz\"\n",
    "\n",
    "tgz_file = \"data/lesson5-pets.tgz\"\n",
    "if not os.path.exists(tgz_file):\n",
    "  lib.download_file(images_url, tgz_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0a2f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "exctracted_dir = \"data/lesson5\"\n",
    "if not os.path.exists(exctracted_dir):\n",
    "  with tarfile.open(tgz_file, \"r\") as t:\n",
    "    t.extractall(\"data/lesson5\")\n",
    "\n",
    "base_dir = os.path.join(exctracted_dir, \"oxford-iiit-pet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e39129",
   "metadata": {},
   "source": [
    "# Examine Data\n",
    "\n",
    "See how the image data is organized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc6d0d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Persian_206.jpg'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_dir = os.path.join(base_dir, \"images\")\n",
    "image_files = os.listdir(images_dir)\n",
    "\n",
    "image_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5596a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "failed to extract breed from image path: data/lesson5/oxford-iiit-pet/images/Abyssinian_101.mat",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m     ys.append(y)\n\u001b[32m     21\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m torch.tensor(xs), torch.tensor(ys)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m x, y = \u001b[43mload_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage_files\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m x.shape, y.shape\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mload_images\u001b[39m\u001b[34m(image_files)\u001b[39m\n\u001b[32m     16\u001b[39m xs, ys = [], []\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m image_files:\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m   x, y = \u001b[43mload_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m   xs.append(x)\n\u001b[32m     20\u001b[39m   ys.append(y)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mload_image\u001b[39m\u001b[34m(img_path)\u001b[39m\n\u001b[32m      8\u001b[39m m = _img_path_re.match(img_path)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfailed to extract breed from image path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m y = m.group(\u001b[33m\"\u001b[39m\u001b[33mbreed\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m x = torchvision.io.decode_image(img_path)\n",
      "\u001b[31mRuntimeError\u001b[39m: failed to extract breed from image path: data/lesson5/oxford-iiit-pet/images/Abyssinian_101.mat"
     ]
    }
   ],
   "source": [
    "import torchvision.io\n",
    "import re\n",
    "import torch\n",
    "\n",
    "_img_path_re = re.compile(r\"^.*/(?P<breed>[^/]+)_\\d+.jpg$\")\n",
    "\n",
    "def load_image(img_path):\n",
    "  m = _img_path_re.match(img_path)\n",
    "  if m is None:\n",
    "    raise RuntimeError(f\"failed to extract breed from image path: {img_path}\")\n",
    "  y = m.group(\"breed\")\n",
    "  x = torchvision.io.decode_image(img_path)\n",
    "  return x, y\n",
    "\n",
    "def load_images(image_files):\n",
    "  xs, ys = [], []\n",
    "  for i in image_files:\n",
    "    x, y = load_image(i)\n",
    "    xs.append(x)\n",
    "    ys.append(y)\n",
    "  return torch.tensor(xs), torch.tensor(ys)\n",
    "\n",
    "x, y = load_images([os.path.join(images_dir, i) for i in image_files])\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44dfaba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([[1, 1, 1, 1], [1, 1, 1, 1]])\n",
    "a.sum(dim=(1), keepdim=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai-lessons",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
